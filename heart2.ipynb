import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

data = pd.read_csv('heart.csv')

print("first few rows : ")
data.head()


print("last few rows : ")
data.tail()

data.isnull()


duplicates = data.duplicated().sum()
print(f"number of duplicate rows : {duplicates}")

data_cleaned = data.drop_duplicates()
print(f"Number of rows after removing duplicates: {data_cleaned.shape[0]}")

missing_values = data_cleaned.isnull().sum()
print("Missing values in each column:")
print(missing_values)

if data_cleaned['Thal'].isnull().sum() > 0:
    mode_value = data_cleaned['Thal'].mode()[0]
    data_cleaned['Thal'] = data_cleaned['Thal'].fillna(mode_value)

if data_cleaned['Ca'].isnull().sum() > 0:
    median_value = data_cleaned['Ca'].median()
    data_cleaned['Ca'] = data_cleaned['Ca'].fillna(median_value)

missing_values_after = data_cleaned.isnull().sum()
print("Missing values in each column after handling:")
print(missing_values_after)

numerical_features = data_cleaned.select_dtypes(include=['int64', 'float64']).columns

scaler = StandardScaler()

data_cleaned[numerical_features] = scaler.fit_transform(data_cleaned[numerical_features])


print("Data after scaling:")
data_cleaned.head()

train_data, test_data = train_test_split(data_cleaned, test_size=0.25, random_state=42)

print("Training data size:", train_data.shape)
print("Testing data size:", test_data.shape)


from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
data[['Age', 'RestBP', 'Chol', 'MaxHR', 'Oldpeak']] = scaler.fit_transform(data[['Age', 'RestBP', 'Chol', 'MaxHR', 'Oldpeak']])

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
data[['Age', 'RestBP', 'Chol', 'MaxHR', 'Oldpeak']] = scaler.fit_transform(data[['Age', 'RestBP', 'Chol', 'MaxHR', 'Oldpeak']])

print("\nColumns after transformation:")
print(data.columns)

data.head()

data['AgeGroup'] = pd.cut(data['Age'], bins=[-3, -1, 0, 2], labels=['Young', 'Middle-aged', 'Senior'])


data.head()
